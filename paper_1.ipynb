{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Define quantum gates\n",
    "HADAMARD = (1 / np.sqrt(2)) * np.array([[1, 1], [1, -1]])\n",
    "T_GATE = np.array([[1, 0], [0, np.exp(1j * np.pi / 4)]])\n",
    "CNOT = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]])\n",
    "\n",
    "\n",
    "# Define the quantum environment\n",
    "class QuantumGateEnv:\n",
    "    def __init__(self, max_steps=10):\n",
    "        self.max_steps = max_steps\n",
    "        self.time_step = 0\n",
    "        self.state = None\n",
    "        self.target = None\n",
    "        self.gate = None\n",
    "\n",
    "    def reset(self, gate=\"H\"):\n",
    "        self.time_step = 0\n",
    "        self.gate = gate\n",
    "        if gate == \"H\":\n",
    "            self.state = np.array([1 + 0j, 0 + 0j], dtype=np.complex128)  # |0> state\n",
    "            self.target = HADAMARD\n",
    "            self.theoretical_state = np.dot(self.target, self.state)\n",
    "        elif gate == \"T\":\n",
    "            self.state = np.array([1 + 0j, 0 + 0j], dtype=np.complex128)  # |0> state\n",
    "            self.target = T_GATE\n",
    "            self.theoretical_state = np.dot(self.target, self.state)\n",
    "        elif gate == \"CNOT\":\n",
    "            self.state = np.array(\n",
    "                [0 + 0j, 0 + 0j, 0 + 0j, 1 + 0j], dtype=np.complex128\n",
    "            )  # |11> state\n",
    "            self.target = CNOT\n",
    "            self.theoretical_state = np.dot(self.target, self.state)\n",
    "        return self._get_full_real_state()\n",
    "\n",
    "    def _get_full_real_state(self):\n",
    "        return np.concatenate((self.state.real, self.state.imag))\n",
    "\n",
    "    def _get_control_matrix(self, action):\n",
    "        theta = np.pi / 8  # Rotation angle\n",
    "        if action == 0:  # Rotation around X-axis\n",
    "            return np.array(\n",
    "                [\n",
    "                    [np.cos(theta / 2), -1j * np.sin(theta / 2)],\n",
    "                    [-1j * np.sin(theta / 2), np.cos(theta / 2)],\n",
    "                ]\n",
    "            )\n",
    "        elif action == 1:  # Rotation around Y-axis\n",
    "            return np.array(\n",
    "                [\n",
    "                    [np.cos(theta / 2), -np.sin(theta / 2)],\n",
    "                    [np.sin(theta / 2), np.cos(theta / 2)],\n",
    "                ]\n",
    "            )\n",
    "        elif action == 2:  # Rotation around Z-axis\n",
    "            return np.array([[np.exp(-1j * theta / 2), 0], [0, np.exp(1j * theta / 2)]])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "    def step(self, action):\n",
    "        self.time_step += 1\n",
    "        control_matrix = self._get_control_matrix(action)\n",
    "        next_state = np.dot(control_matrix, self.state)\n",
    "        self.state = next_state\n",
    "        reward = -self.infidelity(next_state) if self.time_step == self.max_steps else 0\n",
    "        done = self.time_step == self.max_steps\n",
    "        return self._get_full_real_state(), reward, done\n",
    "\n",
    "    def infidelity(self, final_complex_state):\n",
    "        fidelity = np.abs(np.vdot(self.theoretical_state, final_complex_state)) ** 2\n",
    "        return 1 - fidelity\n",
    "\n",
    "\n",
    "# Dueling Double Deep Q-Network\n",
    "class DDDQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DDDQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.value_fc = nn.Linear(64, 1)\n",
    "        self.advantage_fc = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        value = self.value_fc(x)\n",
    "        advantage = self.advantage_fc(x)\n",
    "        q_vals = value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
    "        return q_vals\n",
    "\n",
    "\n",
    "# DDDQN Agent\n",
    "class DDDQNAgent:\n",
    "    def __init__(self, state_size, action_size, device):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.batch_size = 64\n",
    "        self.device = device\n",
    "\n",
    "        self.model = DDDQN(state_size, action_size).to(device)\n",
    "        self.target_model = DDDQN(state_size, action_size).to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.scaler = GradScaler()\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_size)\n",
    "        state = torch.FloatTensor(state).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model(state)\n",
    "        return np.argmax(q_values.cpu().numpy())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "\n",
    "        self.model.train()\n",
    "        self.target_model.eval()\n",
    "\n",
    "        with autocast():\n",
    "            q_vals = self.model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "            next_q_vals = self.target_model(next_states).max(1)[0]\n",
    "            target_q_vals = rewards + (self.gamma * next_q_vals * (1 - dones))\n",
    "            loss = self.criterion(q_vals, target_q_vals)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        self.scaler.scale(loss).backward()\n",
    "        self.scaler.step(self.optimizer)\n",
    "        self.scaler.update()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "\n",
    "# Training the agent\n",
    "def train_agent(agent, env, episodes, target_update, fidelity_threshold):\n",
    "    total_rewards = []\n",
    "    fidelities = []\n",
    "    for e in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        for time in range(env.max_steps):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        agent.replay()\n",
    "        if e % target_update == 0:\n",
    "            agent.update_target_model()\n",
    "        total_rewards.append(total_reward)\n",
    "        fidelity = 1 - env.infidelity(env.state)\n",
    "        fidelities.append(fidelity)\n",
    "        if e % 100 == 0:\n",
    "            print(\n",
    "                f\"Episode: {e}/{episodes}, Total Reward: {total_reward}, Fidelity: {fidelity:.4f}, Epsilon: {agent.epsilon:.2f}\"\n",
    "            )\n",
    "        if fidelity >= fidelity_threshold:\n",
    "            print(f\"Early stopping at episode {e} with fidelity {fidelity}\")\n",
    "            break\n",
    "    return total_rewards, fidelities\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "EPISODES = 10000\n",
    "TARGET_UPDATE = 100\n",
    "FIDELITY_THRESHOLD = 1 - 1e-4\n",
    "\n",
    "# Initialize the environment and agent\n",
    "state_size = 1  # One qubit\n",
    "action_size = 3  # Rotations around X, Y, Z axes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "env = QuantumGateEnv()\n",
    "agent = DDDQNAgent(state_size, action_size, device)\n",
    "\n",
    "# Train the agent\n",
    "total_rewards, fidelities = train_agent(\n",
    "    agent, env, EPISODES, TARGET_UPDATE, FIDELITY_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 203.683x200.667 with 1 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc=QuantumCircuit(2)\n",
    "qc.cx(0,1)\n",
    "qc.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 203.683x200.667 with 1 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc.decompose().draw(output='mpl',style='clifford')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
